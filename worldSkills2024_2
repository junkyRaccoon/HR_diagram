{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPyNWQgVe8VVnabPoRcuXa3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/junkyRaccoon/HR_diagram/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kSW7rzXNsgzF"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emnist_labels = [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122]"
      ],
      "metadata": {
        "id": "OzJNk2u-suMp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q25Jfqy2s4ny",
        "outputId": "bbaa25d7-f430-4500-b93b-7c1e4bbceb46"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras import optimizers\n",
        "from keras.layers import Convolution2D, MaxPooling2D, Dropout, Flatten, Dense, Reshape, LSTM, BatchNormalization\n",
        "from keras.optimizers import SGD, RMSprop, Adam\n",
        "from keras import backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "def emnist_model():\n",
        "    model = Sequential()\n",
        "    model.add(Convolution2D(filters=32, kernel_size=(3, 3), padding='valid', input_shape=(100, 100, 1), activation='relu'))\n",
        "    model.add(Convolution2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(len(emnist_labels), activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "ksue6Rh0s7sb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install idx2numpy\n",
        "import idx2numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlczrnUNs7u8",
        "outputId": "ec81a239-01a8-4f7d-d48a-7e48f7349b19"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting idx2numpy\n",
            "  Downloading idx2numpy-1.2.3.tar.gz (6.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from idx2numpy) (1.25.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from idx2numpy) (1.16.0)\n",
            "Building wheels for collected packages: idx2numpy\n",
            "  Building wheel for idx2numpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for idx2numpy: filename=idx2numpy-1.2.3-py3-none-any.whl size=7904 sha256=d0c4c17070ac3fc334dad6891a92d0a338705b2009c3e314d78bba4094807c19\n",
            "  Stored in directory: /root/.cache/pip/wheels/e0/f4/e7/643fc5f932ec2ff92997f43f007660feb23f948aa8486f1107\n",
            "Successfully built idx2numpy\n",
            "Installing collected packages: idx2numpy\n",
            "Successfully installed idx2numpy-1.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://biometrics.nist.gov/cs_links/EMNIST/gzip.zip\n",
        "!unzip /content/gzip.zip\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from shutil import copy2\n",
        "copy2(\"drive/MyDrive/pizzip.zip\", \".\")\n",
        "!unzip pizzip.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wksYEk8Rs-_U",
        "outputId": "e9e2b8dc-a1a3-4ce3-868e-540004b12b40"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-26 21:42:58--  https://biometrics.nist.gov/cs_links/EMNIST/gzip.zip\n",
            "Resolving biometrics.nist.gov (biometrics.nist.gov)... 18.235.227.114\n",
            "Connecting to biometrics.nist.gov (biometrics.nist.gov)|18.235.227.114|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 561753746 (536M) [application/zip]\n",
            "Saving to: ‘gzip.zip.1’\n",
            "\n",
            "gzip.zip.1          100%[===================>] 535.73M  14.1MB/s    in 41s     \n",
            "\n",
            "2024-03-26 21:43:40 (13.1 MB/s) - ‘gzip.zip.1’ saved [561753746/561753746]\n",
            "\n",
            "Archive:  /content/gzip.zip\n",
            "replace gzip/emnist-balanced-mapping.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: gzip/emnist-balanced-mapping.txt  \n",
            "  inflating: gzip/emnist-balanced-test-images-idx3-ubyte.gz  \n",
            " extracting: gzip/emnist-balanced-test-labels-idx1-ubyte.gz  \n",
            "  inflating: gzip/emnist-balanced-train-images-idx3-ubyte.gz  \n",
            "  inflating: gzip/emnist-balanced-train-labels-idx1-ubyte.gz  \n",
            "  inflating: gzip/emnist-byclass-mapping.txt  \n",
            "  inflating: gzip/emnist-byclass-test-images-idx3-ubyte.gz  \n",
            "  inflating: gzip/emnist-byclass-test-labels-idx1-ubyte.gz  \n",
            "  inflating: gzip/emnist-byclass-train-images-idx3-ubyte.gz  \n",
            "  inflating: gzip/emnist-byclass-train-labels-idx1-ubyte.gz  \n",
            "  inflating: gzip/emnist-bymerge-mapping.txt  \n",
            "  inflating: gzip/emnist-bymerge-test-images-idx3-ubyte.gz  \n",
            "  inflating: gzip/emnist-bymerge-test-labels-idx1-ubyte.gz  \n",
            "  inflating: gzip/emnist-bymerge-train-images-idx3-ubyte.gz  \n",
            "  inflating: gzip/emnist-bymerge-train-labels-idx1-ubyte.gz  \n",
            "  inflating: gzip/emnist-digits-mapping.txt  \n",
            "  inflating: gzip/emnist-digits-test-images-idx3-ubyte.gz  \n",
            "  inflating: gzip/emnist-digits-test-labels-idx1-ubyte.gz  \n",
            "  inflating: gzip/emnist-digits-train-images-idx3-ubyte.gz  \n",
            "  inflating: gzip/emnist-digits-train-labels-idx1-ubyte.gz  \n",
            "  inflating: gzip/emnist-letters-mapping.txt  \n",
            "  inflating: gzip/emnist-letters-test-images-idx3-ubyte.gz  \n",
            " extracting: gzip/emnist-letters-test-labels-idx1-ubyte.gz  \n",
            "  inflating: gzip/emnist-letters-train-images-idx3-ubyte.gz  \n",
            "  inflating: gzip/emnist-letters-train-labels-idx1-ubyte.gz  \n",
            "  inflating: gzip/emnist-mnist-mapping.txt  \n",
            "  inflating: gzip/emnist-mnist-test-images-idx3-ubyte.gz  \n",
            " extracting: gzip/emnist-mnist-test-labels-idx1-ubyte.gz  \n",
            "  inflating: gzip/emnist-mnist-train-images-idx3-ubyte.gz  \n",
            "  inflating: gzip/emnist-mnist-train-labels-idx1-ubyte.gz  \n",
            "Mounted at /content/drive\n",
            "Archive:  pizzip.zip\n",
            "   creating: emnist-byclass-train-images-idx3-ubyte/\n",
            "  inflating: emnist-byclass-train-images-idx3-ubyte/emnist-byclass-train-images-idx3-ubyte  \n",
            "   creating: emnist-byclass-train-labels-idx1-ubyte/\n",
            "  inflating: emnist-byclass-train-labels-idx1-ubyte/emnist-byclass-train-labels-idx1-ubyte  \n",
            "   creating: emnist-byclass-test-images-idx3-ubyte/\n",
            "  inflating: emnist-byclass-test-images-idx3-ubyte/emnist-byclass-test-images-idx3-ubyte  \n",
            "   creating: emnist-byclass-test-labels-idx1-ubyte/\n",
            "  inflating: emnist-byclass-test-labels-idx1-ubyte/emnist-byclass-test-labels-idx1-ubyte  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def to100(img, new_size):\n",
        "    xxtrain = []\n",
        "    for x in range(len(img)):\n",
        "       output = cv2.resize(img[x], new_size, interpolation=cv2.INTER_AREA)\n",
        "       xxtrain.append(output)\n",
        "    return np.array(xxtrain)\n",
        "\n",
        "X_train = idx2numpy.convert_from_file('/content/emnist-byclass-train-images-idx3-ubyte/emnist-byclass-train-images-idx3-ubyte')\n",
        "y_train = idx2numpy.convert_from_file('/content/emnist-byclass-train-labels-idx1-ubyte/emnist-byclass-train-labels-idx1-ubyte')\n",
        "\n",
        "X_test = idx2numpy.convert_from_file('/content/emnist-byclass-test-images-idx3-ubyte/emnist-byclass-test-images-idx3-ubyte')\n",
        "y_test = idx2numpy.convert_from_file('/content/emnist-byclass-test-labels-idx1-ubyte/emnist-byclass-test-labels-idx1-ubyte')\n",
        "\n",
        "k = 10\n",
        "X_train = X_train[:X_train.shape[0] // k]\n",
        "y_train = y_train[:y_train.shape[0] // k]\n",
        "X_test = X_test[:X_test.shape[0] // k]\n",
        "y_test = y_test[:y_test.shape[0] // k]\n",
        "\n",
        "xTrain = to100(X_train, (100, 100))\n",
        "xTest = to100(X_test, (100, 100))\n",
        "\n",
        "print(xTrain.shape, y_train.shape, xTest.shape, y_test.shape, len(emnist_labels))\n",
        "\n",
        "# Normalize\n",
        "X_train = xTrain.astype(np.float32)\n",
        "X_train /= 255.0\n",
        "X_test = xTest.astype(np.float32)\n",
        "X_test /= 255.0\n",
        "\n",
        "x_train_cat = keras.utils.to_categorical(y_train, len(emnist_labels))\n",
        "y_test_cat = keras.utils.to_categorical(y_test, len(emnist_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCJKusB-s_Cb",
        "outputId": "08c3adc7-ae95-408b-ed95-d031448d796b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(69793, 100, 100) (69793,) (11632, 100, 100) (11632,) 62\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = emnist_model()\n",
        "learning_rate_reduction = keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', patience=3, verbose=1, factor=0.5, min_lr=0.00001)\n",
        "model.fit(X_train, x_train_cat, validation_data=(X_test, y_test_cat), callbacks=[learning_rate_reduction], batch_size=64, epochs=50)\n",
        "model.save('emnist_lettersPRO.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKHcja9ltELN",
        "outputId": "5eb2e7f6-d84a-49d6-d9a5-8e65aeda6a70"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1091/1091 [==============================] - 80s 67ms/step - loss: 3.2570 - accuracy: 0.2847 - val_loss: 2.4064 - val_accuracy: 0.4609 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "1091/1091 [==============================] - 71s 66ms/step - loss: 2.2079 - accuracy: 0.4783 - val_loss: 1.8194 - val_accuracy: 0.5659 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "1091/1091 [==============================] - 71s 65ms/step - loss: 1.8593 - accuracy: 0.5445 - val_loss: 1.5817 - val_accuracy: 0.6045 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "1091/1091 [==============================] - 71s 65ms/step - loss: 1.6870 - accuracy: 0.5756 - val_loss: 1.4424 - val_accuracy: 0.6281 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "1091/1091 [==============================] - 71s 65ms/step - loss: 1.5724 - accuracy: 0.5970 - val_loss: 1.3448 - val_accuracy: 0.6468 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "1091/1091 [==============================] - 72s 66ms/step - loss: 1.4953 - accuracy: 0.6098 - val_loss: 1.2701 - val_accuracy: 0.6647 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "1091/1091 [==============================] - 72s 66ms/step - loss: 1.4311 - accuracy: 0.6217 - val_loss: 1.2140 - val_accuracy: 0.6760 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "1091/1091 [==============================] - 71s 65ms/step - loss: 1.3849 - accuracy: 0.6315 - val_loss: 1.1674 - val_accuracy: 0.6861 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "1091/1091 [==============================] - 72s 66ms/step - loss: 1.3410 - accuracy: 0.6414 - val_loss: 1.1278 - val_accuracy: 0.6948 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "1091/1091 [==============================] - 72s 66ms/step - loss: 1.3013 - accuracy: 0.6511 - val_loss: 1.0946 - val_accuracy: 0.7012 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "1091/1091 [==============================] - 72s 66ms/step - loss: 1.2766 - accuracy: 0.6538 - val_loss: 1.0695 - val_accuracy: 0.7066 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "1091/1091 [==============================] - 72s 66ms/step - loss: 1.2512 - accuracy: 0.6618 - val_loss: 1.0432 - val_accuracy: 0.7116 - lr: 0.0010\n",
            "Epoch 13/50\n",
            "1091/1091 [==============================] - 71s 65ms/step - loss: 1.2259 - accuracy: 0.6666 - val_loss: 1.0218 - val_accuracy: 0.7162 - lr: 0.0010\n",
            "Epoch 14/50\n",
            "1091/1091 [==============================] - 72s 66ms/step - loss: 1.2042 - accuracy: 0.6715 - val_loss: 1.0022 - val_accuracy: 0.7221 - lr: 0.0010\n",
            "Epoch 15/50\n",
            "1091/1091 [==============================] - 72s 66ms/step - loss: 1.1883 - accuracy: 0.6741 - val_loss: 0.9855 - val_accuracy: 0.7256 - lr: 0.0010\n",
            "Epoch 16/50\n",
            "1091/1091 [==============================] - 72s 66ms/step - loss: 1.1667 - accuracy: 0.6809 - val_loss: 0.9684 - val_accuracy: 0.7286 - lr: 0.0010\n",
            "Epoch 17/50\n",
            "1091/1091 [==============================] - 72s 66ms/step - loss: 1.1500 - accuracy: 0.6849 - val_loss: 0.9540 - val_accuracy: 0.7337 - lr: 0.0010\n",
            "Epoch 18/50\n",
            "1091/1091 [==============================] - 71s 65ms/step - loss: 1.1390 - accuracy: 0.6849 - val_loss: 0.9404 - val_accuracy: 0.7369 - lr: 0.0010\n",
            "Epoch 19/50\n",
            "1091/1091 [==============================] - 71s 65ms/step - loss: 1.1236 - accuracy: 0.6889 - val_loss: 0.9289 - val_accuracy: 0.7394 - lr: 0.0010\n",
            "Epoch 20/50\n",
            "1091/1091 [==============================] - 72s 66ms/step - loss: 1.1142 - accuracy: 0.6929 - val_loss: 0.9188 - val_accuracy: 0.7413 - lr: 0.0010\n",
            "Epoch 21/50\n",
            "1091/1091 [==============================] - 71s 65ms/step - loss: 1.1024 - accuracy: 0.6933 - val_loss: 0.9094 - val_accuracy: 0.7454 - lr: 0.0010\n",
            "Epoch 22/50\n",
            "1091/1091 [==============================] - 72s 66ms/step - loss: 1.0916 - accuracy: 0.6960 - val_loss: 0.8993 - val_accuracy: 0.7461 - lr: 0.0010\n",
            "Epoch 23/50\n",
            "1091/1091 [==============================] - 72s 66ms/step - loss: 1.0836 - accuracy: 0.6990 - val_loss: 0.8886 - val_accuracy: 0.7479 - lr: 0.0010\n",
            "Epoch 24/50\n",
            "1091/1091 [==============================] - 72s 66ms/step - loss: 1.0716 - accuracy: 0.7022 - val_loss: 0.8834 - val_accuracy: 0.7509 - lr: 0.0010\n",
            "Epoch 25/50\n",
            "1091/1091 [==============================] - 71s 65ms/step - loss: 1.0642 - accuracy: 0.7045 - val_loss: 0.8774 - val_accuracy: 0.7513 - lr: 0.0010\n",
            "Epoch 26/50\n",
            "1091/1091 [==============================] - 72s 66ms/step - loss: 1.0557 - accuracy: 0.7055 - val_loss: 0.8700 - val_accuracy: 0.7521 - lr: 0.0010\n",
            "Epoch 27/50\n",
            "1091/1091 [==============================] - 72s 66ms/step - loss: 1.0499 - accuracy: 0.7064 - val_loss: 0.8612 - val_accuracy: 0.7556 - lr: 0.0010\n",
            "Epoch 28/50\n",
            "1091/1091 [==============================] - 72s 66ms/step - loss: 1.0376 - accuracy: 0.7093 - val_loss: 0.8530 - val_accuracy: 0.7568 - lr: 0.0010\n",
            "Epoch 29/50\n",
            "1091/1091 [==============================] - 71s 65ms/step - loss: 1.0346 - accuracy: 0.7098 - val_loss: 0.8506 - val_accuracy: 0.7587 - lr: 0.0010\n",
            "Epoch 30/50\n",
            "1091/1091 [==============================] - 71s 65ms/step - loss: 1.0281 - accuracy: 0.7123 - val_loss: 0.8425 - val_accuracy: 0.7605 - lr: 0.0010\n",
            "Epoch 31/50\n",
            "1091/1091 [==============================] - 71s 65ms/step - loss: 1.0191 - accuracy: 0.7153 - val_loss: 0.8368 - val_accuracy: 0.7619 - lr: 0.0010\n",
            "Epoch 32/50\n",
            "1091/1091 [==============================] - 72s 66ms/step - loss: 1.0144 - accuracy: 0.7144 - val_loss: 0.8346 - val_accuracy: 0.7622 - lr: 0.0010\n",
            "Epoch 33/50\n",
            "1091/1091 [==============================] - 71s 65ms/step - loss: 1.0063 - accuracy: 0.7159 - val_loss: 0.8287 - val_accuracy: 0.7618 - lr: 0.0010\n",
            "Epoch 34/50\n",
            "1091/1091 [==============================] - 71s 65ms/step - loss: 1.0039 - accuracy: 0.7185 - val_loss: 0.8235 - val_accuracy: 0.7649 - lr: 0.0010\n",
            "Epoch 35/50\n",
            "1091/1091 [==============================] - 72s 66ms/step - loss: 0.9976 - accuracy: 0.7198 - val_loss: 0.8202 - val_accuracy: 0.7668 - lr: 0.0010\n",
            "Epoch 36/50\n",
            "1091/1091 [==============================] - 72s 66ms/step - loss: 0.9901 - accuracy: 0.7211 - val_loss: 0.8142 - val_accuracy: 0.7656 - lr: 0.0010\n",
            "Epoch 37/50\n",
            "1091/1091 [==============================] - 72s 66ms/step - loss: 0.9913 - accuracy: 0.7227 - val_loss: 0.8138 - val_accuracy: 0.7658 - lr: 0.0010\n",
            "Epoch 38/50\n",
            "1091/1091 [==============================] - 72s 66ms/step - loss: 0.9853 - accuracy: 0.7213 - val_loss: 0.8089 - val_accuracy: 0.7682 - lr: 0.0010\n",
            "Epoch 39/50\n",
            "1091/1091 [==============================] - 72s 66ms/step - loss: 0.9751 - accuracy: 0.7252 - val_loss: 0.8032 - val_accuracy: 0.7686 - lr: 0.0010\n",
            "Epoch 40/50\n",
            "1091/1091 [==============================] - 71s 65ms/step - loss: 0.9704 - accuracy: 0.7271 - val_loss: 0.8027 - val_accuracy: 0.7682 - lr: 0.0010\n",
            "Epoch 41/50\n",
            "1091/1091 [==============================] - 72s 66ms/step - loss: 0.9667 - accuracy: 0.7266 - val_loss: 0.7967 - val_accuracy: 0.7702 - lr: 0.0010\n",
            "Epoch 42/50\n",
            "1091/1091 [==============================] - 72s 66ms/step - loss: 0.9659 - accuracy: 0.7270 - val_loss: 0.7945 - val_accuracy: 0.7727 - lr: 0.0010\n",
            "Epoch 43/50\n",
            "1091/1091 [==============================] - 71s 66ms/step - loss: 0.9625 - accuracy: 0.7262 - val_loss: 0.7933 - val_accuracy: 0.7712 - lr: 0.0010\n",
            "Epoch 44/50\n",
            "1091/1091 [==============================] - 72s 66ms/step - loss: 0.9567 - accuracy: 0.7283 - val_loss: 0.7899 - val_accuracy: 0.7729 - lr: 0.0010\n",
            "Epoch 45/50\n",
            "1091/1091 [==============================] - 72s 66ms/step - loss: 0.9526 - accuracy: 0.7304 - val_loss: 0.7859 - val_accuracy: 0.7716 - lr: 0.0010\n",
            "Epoch 46/50\n",
            "1091/1091 [==============================] - 72s 66ms/step - loss: 0.9425 - accuracy: 0.7326 - val_loss: 0.7815 - val_accuracy: 0.7737 - lr: 0.0010\n",
            "Epoch 47/50\n",
            "1091/1091 [==============================] - 72s 66ms/step - loss: 0.9482 - accuracy: 0.7325 - val_loss: 0.7810 - val_accuracy: 0.7740 - lr: 0.0010\n",
            "Epoch 48/50\n",
            "1091/1091 [==============================] - 71s 65ms/step - loss: 0.9425 - accuracy: 0.7319 - val_loss: 0.7773 - val_accuracy: 0.7742 - lr: 0.0010\n",
            "Epoch 49/50\n",
            "1091/1091 [==============================] - 71s 66ms/step - loss: 0.9380 - accuracy: 0.7321 - val_loss: 0.7757 - val_accuracy: 0.7736 - lr: 0.0010\n",
            "Epoch 50/50\n",
            "1091/1091 [==============================] - 72s 66ms/step - loss: 0.9400 - accuracy: 0.7334 - val_loss: 0.7729 - val_accuracy: 0.7759 - lr: 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/emnist_lettersPRO.h5 /content/drive/MyDrive"
      ],
      "metadata": {
        "id": "SWq1wRxrtEQG"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "brscStPWHOBE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
